{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cf64d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T17:24:21.421431Z",
     "start_time": "2022-04-18T17:24:20.947142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOutput: .tsv with sequence id,  GC count, and GC density\\n\\nInput: .bed file.\\n\\nFunctions: \\n- phastCons split_msa function\\n\\nNotes\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import argparse\n",
    "from collections import Counter\n",
    "import configparser\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/dors/capra_lab/users/fongsl/tools/py_/\")\n",
    "sys.path.append(\"/dors/capra_lab/users/fongsl/tools/genome/\")\n",
    "\n",
    "import config_readwrite as crw\n",
    "import chr_functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Output: .tsv with sequence id,  GC count, and GC density\n",
    "\n",
    "Input: .bed file.\n",
    "\n",
    "Functions: \n",
    "- phastCons split_msa function\n",
    "\n",
    "Notes\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28e51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-13T21:55:43.098594Z",
     "start_time": "2022-04-13T21:55:42.640795Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "###\n",
    "#   arguments\n",
    "###\n",
    "\n",
    "arg_parser = argparse.ArgumentParser(description= \"compute sequence identity between two species\")\n",
    "\n",
    "arg_parser.add_argument(\"b\",\"--bedfile\", help='.bed file in species 1 coordinates')\n",
    "arg_parser.add_argument(\"s\",\"--subject\", help='subject - name species 1 (e.g. hg38)')\n",
    "arg_parser.add_argument(\"q\",\"--query\", help='query - name species 2 (e.g. rheMac10)')\n",
    "arg_parser.add_argument(\"wd\",\"--working_directory\", help='working directory to save results')\n",
    "arg_parser.add_argument(\"a\",\"--alignment\", help='options = hg38.rheMac10, multiz100way, multiz30way, multiz20way')\n",
    "\n",
    "args = arg_parser.parse_args()\n",
    "TEST_BED = args.bedfile\n",
    "SUBJECT= args.subject\n",
    "QUERY = args.query\n",
    "WD = args.working_directory \n",
    "ALIGNMENT = args.alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7b0665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T17:55:26.508580Z",
     "start_time": "2022-04-18T17:55:26.501296Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_BED = \"/dors/capra_lab/users/fongsl/tools/unit_test/test.bed\"\n",
    "\n",
    "TEST_BED = \"/data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles/shuf-all_uniq_diffAct_regions-0.bed\"\n",
    "SUBJECT, QUERY = 'hg38', 'rheMac10'\n",
    "WD = os.path.dirname(TEST_BED)\n",
    "ALIGNMENT = \"hg38.rheMac10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13cf53ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T17:55:27.355711Z",
     "start_time": "2022-04-18T17:55:27.347651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ab0a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T17:25:46.002731Z",
     "start_time": "2022-04-18T17:25:45.993812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5d7f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T19:56:56.161105Z",
     "start_time": "2022-04-18T19:56:56.077046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles/chr-all_uniq_diffAct_regions all_uniq_diffAct_regions /data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles,/data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles/chr-all_uniq_diffAct_regions\n"
     ]
    }
   ],
   "source": [
    "# write these directories, files\n",
    "#for n in range(10):\n",
    " #   TEST_BED = f\"/data/hodges_lab/ATAC-STARR_B-cells/data/hansen-fong/bkgd_sharedAcc_regions/shuffles/shuf-all_uniq_diffAct_regions-{n}.bed\"\n",
    "    TEST_BED = \"/data/hodges_lab/ATAC-STARR_B-cells/results/results_human-evolution/regions/all_uniq_diffAct_regions.bed\"\n",
    "    sample_id = os.path.splitext(os.path.basename(TEST_BED))[0]\n",
    "    chr_path = os.path.join(WD,  f\"chr-{sample_id}\")\n",
    "    SEQID_DATA_RAW = os.path.join(WD, f\"{sample_id}-seq_identity_raw.tsv\")\n",
    "    SEQONLY_DATA = os.path.join(WD, f\"{sample_id}-seq_only.tsv\")\n",
    "    SEQID_DATA = os.path.join(WD, f\"{sample_id}-seq_identity.tsv\")\n",
    "\n",
    "    PATHS = [WD, chr_path]\n",
    "    DATA_PATHS = \",\".join(PATHS)\n",
    "\n",
    "    print(chr_path, sample_id, DATA_PATHS)\n",
    "\n",
    "    ### \n",
    "    # Functions\n",
    "    ### \n",
    "\n",
    "    def make_paths(data_paths):\n",
    "\n",
    "        if type(data_paths) is list:\n",
    "            data_paths = \",\".join(data_paths)\n",
    "\n",
    "        for i, path in enumerate(data_paths.split(\",\")):\n",
    "\n",
    "            if os.path.exists(path) is False:\n",
    "\n",
    "                os.mkdir(path)\n",
    "                print(\"made\", i, path)\n",
    "\n",
    "    def split_chr(test_bed, chr_path):\n",
    "\n",
    "        chr_functions.split_into_chr_bed(test_bed, chr_path)\n",
    "\n",
    "\n",
    "    def get_maf_src(chr_, subject):\n",
    "\n",
    "        # return species' chromosome.maf file\n",
    "\n",
    "        maf_path = f'/dors/capra_lab/data/ucsc/{subject}'\n",
    "        maf_chr = os.path.join(maf_path, ALIGNMENT, f\"{chr_}.maf\") \n",
    "\n",
    "        return maf_chr\n",
    "\n",
    "\n",
    "    def msa_split_x_bed(chr_, chr_bed, path, chr_raw_path): # msa\n",
    "\n",
    "        \"\"\"\n",
    "        1. go to path of bed file\n",
    "        2. get chr-specific maf file in subject genome\n",
    "        3. write feat-arg string\n",
    "        4. write outroot arg string\n",
    "        5. write msa_split cmd string\n",
    "        6. check that .fa files have not been split already. \n",
    "        7. if not, split\n",
    "        8. return list of .fa files - there are N .fa files for N rows of the bed file. \n",
    "        split msa by bed file. \n",
    "        use phast Suite's msa_split function w/ --for-features to split on bedfile .\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        msa_split_bin = \"/dors/capra_lab/bin/./msa_split\"\n",
    "\n",
    "        #1\n",
    "        os.chdir(path)\n",
    "\n",
    "        #2\n",
    "        maf_file = get_maf_src(chr_, SUBJECT)\n",
    "\n",
    "        #3\n",
    "        feat_arg = f\"--features {chr_bed} --for-features\"  # --for-features will split on each row of bed file. \n",
    "\n",
    "        #4\n",
    "        out_root_arg = f\"--out-root {chr_}\"\n",
    "\n",
    "        #5\n",
    "        cmd = f\"{msa_split_bin} {maf_file} --in-format MAF {feat_arg} {out_root_arg}\"\n",
    "\n",
    "        #6\n",
    "        already_split = len(glob.glob(f\"{chr_}*.fa\"))  # outputs lines (as individual files) \n",
    "\n",
    "        n_lines = sum(1 for line in open(chr_bed))  # input lines (from one file) \n",
    "\n",
    "        #7\n",
    "        if already_split !=n_lines:\n",
    "            print(cmd)\n",
    "            subprocess.call(cmd, shell = True)\n",
    "\n",
    "        else:\n",
    "            print(\"done\")\n",
    "        #8\n",
    "        already_split = glob.glob(f\"{chr_}*.fa\")\n",
    "\n",
    "        return already_split\n",
    "\n",
    "\n",
    "\n",
    "    # msasplit indexes by 1. Need to reindex at zero. \n",
    "    def reset_zero_index(coordinate):\n",
    "        coordinate = int(coordinate) -1\n",
    "        return coordinate\n",
    "\n",
    "\n",
    "\n",
    "    def get_percent_identity(subjSeq, querySeq):\n",
    "\n",
    "        lenSeq = len(subjSeq) # get the length of the sequence alignment.\n",
    "\n",
    "        count_identical = 0\n",
    "        count_gap = 0\n",
    "        count_non_identical = 0\n",
    "\n",
    "        # parse through sequence and ask if alignments match. \n",
    "        for a,b in zip(subjSeq,querySeq):\n",
    "\n",
    "            if a==b:\n",
    "                count_identical+=1  # count identical bases\n",
    "\n",
    "            elif a != b:\n",
    "                count_non_identical +=1  # count non-identical bases\n",
    "\n",
    "            if a == \"-\" or b == \"-\":\n",
    "                count_gap +=1  # count gap bases\n",
    "\n",
    "        percent = count_identical/lenSeq  # return percent identity\n",
    "\n",
    "        return count_identical, count_gap, percent\n",
    "\n",
    "\n",
    "    # In[10]:\n",
    "\n",
    "\n",
    "    def make_region_df(fa_handle, sub_seq, qry_seq, subsize, qrysize, score, gap, percent):\n",
    "\n",
    "        chr_, coor = fa_handle.split(\".\")[0:2]\n",
    "        start, end = coor.split(\"-\")\n",
    "\n",
    "        start= reset_zero_index(start) #, reset_zero_index(end)  # 0-index instead of 1-index\n",
    "\n",
    "        df = pd.DataFrame({  # make a dataframe of the results\n",
    "        \"#chr\" :[chr_],\n",
    "        \"start\":[start],\n",
    "        \"end\":[end],\n",
    "        f\"{SUBJECT}_Seqlen\": [subsize],\n",
    "        f\"{QUERY}_Seqlen\": [qrysize],\n",
    "        f\"{SUBJECT}_seq\":sub_seq,\n",
    "        f\"{QUERY}_seq\":qry_seq,\n",
    "        \"score\":[score],\n",
    "        \"gap\":[gap],\n",
    "        \"percent_identity\":[percent],\n",
    "\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    # In[11]:\n",
    "\n",
    "\n",
    "    def make_block_df(results_dict, chr_, path):\n",
    "\n",
    "        # concat the dictionary\n",
    "        re = pd.concat(results_dict.values()).drop_duplicates()\n",
    "        re_seq = re[['#chr', 'start', 'end',f'{SUBJECT}_seq', f'{QUERY}_seq']].copy()\n",
    "        re = re[[\n",
    "                '#chr', 'start', 'end',\n",
    "                f'{SUBJECT}_Seqlen', f'{QUERY}_Seqlen',\n",
    "                'score', 'gap', 'percent_identity',\n",
    "                ]]\n",
    "\n",
    "        # write identity outfile\n",
    "        outf = f\"{chr_}_seq_identity.tsv\"\n",
    "        out = os.path.join(path, outf)\n",
    "\n",
    "        # write identity outfile\n",
    "        outf_seq = f\"{chr_}_seq_only.tsv\"\n",
    "        outseq = os.path.join(path, outf_seq)\n",
    "\n",
    "        # write the files\n",
    "        re.to_csv(out, sep = '\\t', index = False)\n",
    "        re_seq.to_csv(outseq, sep = '\\t', index = False)\n",
    "\n",
    "        return re\n",
    "\n",
    "\n",
    "    # In[12]:\n",
    "\n",
    "\n",
    "    def concat(path):\n",
    "\n",
    "        \"\"\"\n",
    "        (1) go to path\n",
    "        (2) concat chr*_seq_identity.tsv files\n",
    "        (3) remove chromosome-specific seq_identity.tsv files\n",
    "        (4) concat chr*_seq_only.tsv files\n",
    "        (5) remove chromosome-specific seq_only.tsv files\n",
    "        (6) intersect seq_id w/ original bed file\n",
    "        \"\"\"\n",
    "        #(1)\n",
    "        os.chdir(path)\n",
    "\n",
    "        #(2)\n",
    "        cmd = f'cat *_seq_identity.tsv > {SEQID_DATA_RAW}'\n",
    "\n",
    "        #(3)\n",
    "        if os.path.exists(SEQID_DATA_RAW) is False or os.path.getsize(SEQID_DATA_RAW) ==0:\n",
    "            subprocess.call(cmd, shell = True)\n",
    "\n",
    "            cmd = 'rm *_seq_identity.tsv' # clean up\n",
    "            #subprocess.call(cmd, shell = True)\n",
    "        else:\n",
    "            print(\"\\nmade seqid_data\\n\")\n",
    "        #(4) \n",
    "        cmd = f'cat *_seq_only.tsv > {SEQONLY_DATA}'\n",
    "        #(5)\n",
    "        if os.path.exists(SEQONLY_DATA) is False or os.path.getsize(SEQONLY_DATA) ==0:\n",
    "            subprocess.call(cmd, shell = True)\n",
    "\n",
    "            cmd = 'rm *_seq_only.tsv' # clean up\n",
    "            #subprocess.call(cmd, shell = True)\n",
    "        else:\n",
    "            print(\"\\nmade seqonly_data\\n\")\n",
    "\n",
    "        # (6) keep only the files that overlap 90% of an identity tile\n",
    "        cmd = f\"bedtools intersect -a {TEST_BED} -b {SEQID_DATA_RAW} -f 0.9 -wao > {SEQID_DATA}\"\n",
    "        subprocess.call(cmd, shell = True)\n",
    "\n",
    "\n",
    "    def extract_fa_data(fa_handle):\n",
    "        if os.path.exists(fa_handle) is True:  # check that the path exists\n",
    "            with open(fa_handle, \"r\") as fa_reader:\n",
    "                \"\"\"\n",
    "                (1) set empty values for collecting species' sequence and sequence size\n",
    "                (2) if species is human, set species variable to human\n",
    "                (3) else, set species variable to rhesus\n",
    "                (4) if neither hg38 or rheMac10 annotation, use species variable to recore sequence, size\n",
    "                \"\"\"\n",
    "                #(1)\n",
    "\n",
    "                sub_seq, qry_seq = \"\", \"\"\n",
    "                subsize, qrysize = 0,0\n",
    "                species = None\n",
    "\n",
    "                for i, line in enumerate(fa_reader):\n",
    "\n",
    "\n",
    "                    #(2)\n",
    "                    if SUBJECT in line:\n",
    "                        species = SUBJECT\n",
    "                    #(3)\n",
    "                    elif QUERY in line:\n",
    "                        species = QUERY\n",
    "                    #(4)\n",
    "                    else:\n",
    "\n",
    "                        line = line.strip(\"\\n\")  # strip the \\n\n",
    "                        if species == SUBJECT:\n",
    "                            sub_seq += line\n",
    "                            subsize += len(line)\n",
    "                        elif species == QUERY:\n",
    "                            qry_seq += line\n",
    "                            qrysize += len(line)\n",
    "                    #os.remove(fa_handle)  # delete the handle\n",
    "\n",
    "        else:\n",
    "            print(\"no fa\", fa_handle)\n",
    "            sub_seq, qry_seq, subsize, qrysize = None, None, -1, -1\n",
    "        return sub_seq, qry_seq, subsize, qrysize\n",
    "\n",
    "\n",
    "    def make_chr_files(chr_, working_dir, chr_path):\n",
    "        outf = os.path.join(working_dir, f\"{chr_}_seq_identity.tsv\")  # chr-seq identity file to write\n",
    "        chrF = f\"{chr_}.bed\"  # regions to do msasplit on. \n",
    "        chr_bed = os.path.join(chr_path, chrF)  # with full path. \n",
    "\n",
    "        return outf, chrF, chr_bed\n",
    "\n",
    "\n",
    "    def main(argv):\n",
    "\n",
    "        chrList = chr_functions.make_chr_list()  # get chromosomes\n",
    "\n",
    "        if os.path.exists(SEQID_DATA) is False:   \n",
    "\n",
    "            \"\"\"\n",
    "            (0) Make output paths\n",
    "            (1) split file by chromosome number\n",
    "            \"\"\"\n",
    "\n",
    "            #(0)\n",
    "            make_paths(DATA_PATHS)\n",
    "\n",
    "            #(1)\n",
    "            split_chr(TEST_BED, chr_path) \n",
    "\n",
    "\n",
    "            for chr_ in chrList:  \n",
    "                \"\"\"\n",
    "                per chromosome this section will\n",
    "                (2) perform msa_splits \n",
    "                (3) quantify sequence identity\n",
    "                \"\"\"\n",
    "\n",
    "                print(chr_)\n",
    "\n",
    "                outf, chrF, CHR_BED = make_chr_files(chr_, WD, chr_path)\n",
    "\n",
    "\n",
    "                #(2) perform msa_splits\n",
    "                if os.path.exists(outf) is False or os.path.getsize(outf) ==0:\n",
    "\n",
    "                    msa_splits = msa_split_x_bed(chr_, CHR_BED, WD, chr_path) # MSA\n",
    "                    print(msa_splits, \"\\n\\n finished splitting \\n\\n\")\n",
    "\n",
    "                    results_dict = {}  # for collecting data on sequence identity\n",
    "\n",
    "                    #(3) quantify sequence identity\n",
    "                    for n, fa_handle in enumerate(msa_splits):\n",
    "\n",
    "                        if n%10000 == 0 and n !=0:\n",
    "                            print(n)\n",
    "\n",
    "                        os.chdir(WD)\n",
    "\n",
    "                        sub_seq, qry_seq, subsize, qrysize = extract_fa_data(fa_handle)\n",
    "\n",
    "                        os.remove(fa_handle) ## remove the handle\n",
    "\n",
    "                        count_identical, count_gap, percent = get_percent_identity(sub_seq, qry_seq)\n",
    "\n",
    "                        df = make_region_df(fa_handle, sub_seq, qry_seq, subsize, qrysize, count_identical, count_gap, percent)\n",
    "\n",
    "                        results_dict[n] = df\n",
    "\n",
    "                    re = make_block_df(results_dict, chr_, WD)  # write the results ot a file\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            (4) consolidate each chromosomes' dataframe\n",
    "            \"\"\"\n",
    "            #re = make_block_df(results_dict, chr_, WD)\n",
    "\n",
    "            \"\"\"\n",
    "            (5) concatenate all chromosome results and intersect w/ original file. \n",
    "\n",
    "            \"\"\"\n",
    "            concat(WD) \n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e24fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T17:24:16.292524Z",
     "start_time": "2022-04-18T17:24:16.169284Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SEQID_DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7fcc0d37b7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSEQID_DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SEQID_DATA' is not defined"
     ]
    }
   ],
   "source": [
    "SEQID_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c53956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfenv)",
   "language": "python",
   "name": "sfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
